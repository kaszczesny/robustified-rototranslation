\chapter{Discussion of results}
\label{cha:results}

% global results for various datasets
This chapter focuses on discussing overall algorithm results obtained from longer sequences. Tested sequences come from TUM \cite{tum} and KITTI \cite{kitti} public datasets. Results include comparison of $x$, $y$ and $z$ components of the estimated camera trajectory with ground truth, as well as numeric quantities (Table~\ref{tab:drift}). Some erroneous outcomes are also presented, with brief commentary.

\section{Experimental setup}

All of the tested sequences include ground truth (either laser positioning system in case of TUM, or  Differential GPS in case of KITTI), which is essential for debugging and validation purposes. Also, these datasets are commonly used for visual odometry systems evaluation, making to possible to compare proposed algorthim with others. Intrinsic camera parameters were reported by dataset authors.

As the main goal of the algorithm is to estimate transformation between images, most care was put into making sure that the system correctly calculates position of the camera in respect to ground truth. Obtained trajectory was fitted onto ground truth trajectory using method explained in Section~\ref{sec:fitting}.

Algorithm itself was implemented in the GNU Octave environment. The OpenCV \cite{opencv} library was also used; it was complied to MEX files, that can be executed by Octave. Choice of programming language enabled fast prototyping and easy visualization, but prevented the algorithm from achieving real-time performance. Based on results in \cite{jose2015realtime} it is estimated that implementation in a compiled language such as C++ would accomplish such goal even on a~consumer-grade smartphone.

In order to speed up computations, images were first scaled down. This removed some false edges, while retaining only the strongest ones, thus greatly reducing the number of Keylines. In \cite{jose2015realtime} it was already shown that algorithm run time depends linearly on Keyline number. The biggest downscaling factor was reduction of size by 80\%, resulting in an 128 by 96 pixels wide image. Although such images are too small to be easily interpreted by humans, algorithm results were still satisfactory.

Comparison of time needed to process one frame with two different downscaling factors is featured in Fig.~\ref{fig:timing}. For these particular images and scales, larger scale resulted in $1.81$ more processing time per frame, on average. Measured time included creation of some visualization files, but this factor was insignificant next to the most time-consuming step, i.e.~the minimization.

\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={0.0cm 1.0cm 1.5cm 0.0cm},clip]{img/figures/frametime.png}
	\caption{ Single frame processing time for TUM fr3\_teddy sequence. Red line corresponds to scale of $\frac{1}{3}$ of original image; blue line~\==~ $\frac{1}{5}$ }
	\label{fig:timing}
\end{figure}


A few system parameters had to be adjusted between TUM and KITTI datasets, but there was no need of fine tuning the configuration for every sequence separately.

\section{Trajectory comparison}

Presented results consists mainly from the following sequences:
\begin{itemize}
	\item TUM fr1\_xyz - only translatory motions are present here, as stated by creators of this dataset "\textit{it's mainly for debugging purposes}",
	\item TUM fr2\_desk - slow sweep around an office desk,
	\item TUM fr2\_desk\_with\_person - same as above, but present person moves the objects around, creating outliers,
	\item TUM fr2\_pioneer\_SLAM - robot with a mounted camera is trying to self-localize and map the room,
	\item TUM fr3\_long\_office\_household - slow sweep around two desks,
	\item TUM fr3\_teddy - slow sweep around a big plush teddy bear,
	\item KITTI 01 - video taken from a camera mounted in front of a car.
\end{itemize}

todo: ogólnie było dobrze gdy ... A view from top of a trajectory is presented in Fig.~\ref{fig:traject}. Despite the low number of frame, complex motion has been recovered relatively closely. Even in a dataset containing outliers (independently moving objects), odometry was correct (see Fig.~\ref{fig:trajectxyz}).

\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={1.0cm 1.0cm 1.5cm 1.0cm},clip]{img/figures/deskperson_trajectory.png}
	\caption{ Example trajectory comparison between obtained results and ground truth from dataset TUM fr2\_desk\_with\_person, projected on the $y=0$ plane, as camera height was the least significant motion component. }
	\label{fig:traject}
\end{figure}

\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={1.0cm 1.0cm 1.5cm 1.0cm},clip]{img/figures/deskperson_xyz.png}
	\caption{ Example trajectory components comparison between obtained results and ground truth from dataset TUM fr2\_desk\_with\_person. Red line marks estimated position; blue~\==~ground truth; black circles~\==~reinitialization }
	\label{fig:trajectxyz}
\end{figure}

Sometimes frames did not contain enough Keylines and system had to be reinitialized. In case of TUM fr3\_teddy sequence there are 4 cases of reinitialization: frames 271 \& 272, 280, 386 \& 387, 394, as shown in Fig.~\ref{fig:teddyfull}. System recovered from three out of four of them, but the third was fatal in a sense that scale and starting rototranslation were lost, and in extension that trajectory as a whole can not be well fitted with ground truth (Fig.~\ref{fig:teddynok}). However, partitioned sections can and are fitted quite well, shown on Fig.~\ref{fig:teddy1} and Fig.~\ref{fig:teddy2} for the first part and a second one, respectively. Such points could be potentially detected in post-processing, as they are a sharp mark of a otherwise smooth 3D curve.

\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={1.0cm 1.0cm 1.5cm 1.0cm},clip]{img/figures/teddy_full.png}
	\caption{ Whole trajectory with denoted cases of reinitialization from dataset TUM fr3\_teddy. Red line marks estimated position; blue~\==~ground truth; black circles~\==~reinitialization }
	\label{fig:teddyfull}
\end{figure}
\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={1.0cm 1.0cm 1.5cm 1.0cm},clip]{img/figures/teddy_nok.png}
	\caption{ Fitted trajectory showing fatal reinitialization problem from dataset TUM fr3\_teddy. Red line marks estimated position; blue~\==~ground truth; black circles~\==~reinitialization }
	\label{fig:teddynok}
\end{figure}
\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={1.0cm 1.0cm 1.5cm 1.0cm},clip]{img/figures/teddy_1.png}
	\caption{ First part of the sequence fitted to ground truth from dataset TUM fr3\_teddy. Red line marks estimated position; blue~\==~ground truth; black circles~\==~reinitialization }
	\label{fig:teddy1}
\end{figure}
\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={1.0cm 1.0cm 1.5cm 1.0cm},clip]{img/figures/teddy_2.png}
	\caption{ Second part of the sequence fitted to ground truth from dataset TUM fr3\_teddy. Red line marks estimated position; blue~\==~ground truth; black circles~\==~reinitialization }
	\label{fig:teddy2}
\end{figure}

This reinitialization in particular is interesting, because of a depth estimation artifact. Movement in this sequence is a circle around the teddy bear - in every frame camera moves and rotates a bit, to always have the teddy bear in the middle of the picture frame. This causes the toy's edges to be more or less in the same spot, while edges of the environment are shifted a bit more. This can lead to the system estimating that if the edges of this object (lying closest in real life) don't move a lot, they have to be very far away, and the rest is closer. Example of such bad initialization is presented in Fig~\ref{fig:teddyflip}.

\begin{figure}[ht]
	\centering
	\begin{subfigure}{1\textwidth}
		\centering
		\centering\includegraphics[width=0.3\linewidth]{img/figures/flip/14_0756.png}
		\subcaption{\label{fig:teddyfirst}}
	\end{subfigure}
	\begin{subfigure}{1\textwidth}
		\centering
		\centering\includegraphics[width=0.3\linewidth]{img/figures/flip/14_1088.png}
		\subcaption{\label{fig:teddybefore}}
	\end{subfigure}
	\begin{subfigure}{1\textwidth}
		\centering
		\centering\includegraphics[width=0.3\linewidth]{img/figures/flip/14_1094.png}
		\subcaption{\label{fig:teddyafter}}
	\end{subfigure}
	\begin{subfigure}{1\textwidth}
		\centering
		\centering\includegraphics[width=0.3\linewidth]{img/figures/flip/14_1172.png}
		\subcaption{\label{fig:teddylast}}
	\end{subfigure}
	\caption{\label{fig:teddyflip} An example of bad depth initialization (the warmer, the more distanced from the camera object is) \protect\subref{teddyfirst} Well-initialized depth, protect\subref{teddybefore} Depth before the reinitialization, protect\subref{teddyafter} Depth after the reinitialization,
		\protect\subref{fig:teddylast} Badly initialized depth after a few frames}
\end{figure}

The KITTI dataset was far more challenging than TUM. It very often happens that through many consecutive frames, one half of images systematically lack Keylines, affecting the algorithm. As camera was mounted on a car, individual displacements are more rapid. It is even possible that rolling shutter problem is present, although this was not tested. Another issue is that when car is moving forward, many Keylines are present in the middle of the field of view. They undergo little to no displacement between frames, therefore they might bias the minimization and prevent other Keylines from being matched (in the described scenario edges moderately close to image border contain most information about motion of the camera, due to visible disparity). A trajectory estimated for one of KITTI sequences in depicted in Fig~\ref{kitti_3}. These results are rather disheartening, as they show that algorithm need to be improved before it can be employed in urban scenarios for which it was originally planned.



\begin{figure}[ht]
	\centering\includegraphics[width=0.75\linewidth, trim={1.0cm 1.5cm 1.5cm 1.0cm},clip]{img/figures/todo.png}
	\caption{ Estimated trajectory KITTI sequence Second part of the sequence fitted to ground truth from dataset TUM fr3\_teddy. Red line marks estimated position; blue~\==~ground truth; black circles~\==~reinitialization }
	\label{fig:kitti_3}
\end{figure}

% moze cos o tym household, ja tego nie mam
%  KITTI tez by bylo ok





%sredni blad/dryft
%jakas tabelka moze? trzeba to w sensie sredniokwadratowym obliczyc

%long office ok3- 3.6038m/s
%teddy long - 1.8033m/s
%teddy short - 0.57838m/s
%desk with person outlier rej - 0.43574m/s
%				 outlier depth - 0.092159m/s

\begin{table}[ht]
	\centering
	
	\begin{threeparttable}
		\caption{Algorithm results for selected sequences}
		\label{tab:drift}
		
		\begin{tabularx}{1.0\textwidth}{C{0.4} C{0.2} C{0.1} C{0.2}}
			\toprule
			\thead{Sequence} & \thead{Average drift [$\frac{m}{s}$]} & \thead{Scale} & \thead{Cumulative drift [m]} \\
			\midrule
			TUM fr3\_long\_office\_household & $3.6$ & 1.6 \\
			TUM fr3\_teddy (long subsequence) & $1.8$ & 1.1 \\
			TUM fr3\_teddy (short subsequence) & $0.6$ & 1.5 \\
			TUM fr2\_desk\_with\_person & $0.4$ & 1.05 \\
			TUM fr2\_desk\_with\_person & $0.1$ & 1.69 \\
			KITTI 01 & ? & ? \\
			\bottomrule
		\end{tabularx}
		
	\end{threeparttable}
\end{table}

%nok, figura z  edgefindera

%ciekawostki




